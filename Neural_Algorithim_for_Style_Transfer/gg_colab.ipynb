{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd /content/drive/MyDrive/Image_Style_Transfer/Neural_Algorithim_for_Style_Transfer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import config\n",
    "import losses\n",
    "import preprocessing\n",
    "import helpers\n",
    "import argparse\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from style_content_model import StyleContentModel\n",
    "\n",
    "def train(epochs: int, content_image, style_image):\n",
    "    \"\"\"Train generated image\n",
    "\n",
    "    @param epochs: Number of epochs to train model\n",
    "    @param content_image: Content image\n",
    "    @param style_image: Style image\n",
    "\n",
    "    @return generated_image\n",
    "    \"\"\"\n",
    "    # Initialize extractor\n",
    "    extractor = StyleContentModel(\n",
    "        content_layers=config.CONTENT_LAYERS, style_layers=config.STYLE_LAYERS\n",
    "    )\n",
    "\n",
    "    # Initialize generated image\n",
    "    input_image = tf.Variable(content_image)\n",
    "\n",
    "    # Initilize optimizer\n",
    "    optim = keras.optimizers.Adam(\n",
    "        learning_rate=config.LEARNING_RATE, epsilon=1e-1, beta_1=0.99\n",
    "    )\n",
    "\n",
    "    # Calculate content targets and style targets\n",
    "    content_targets = extractor(content_image)[\"content\"]\n",
    "    style_targets = extractor(style_image)[\"style\"]\n",
    "\n",
    "    with tqdm(range(epochs)) as pbar:\n",
    "        for epoch in pbar:\n",
    "            with tf.GradientTape() as tape:\n",
    "                # Calculate content outputs and style outputs\n",
    "                generated_outputs = extractor(input_image)\n",
    "\n",
    "                content_outputs, style_outputs = (\n",
    "                    generated_outputs[\"content\"],\n",
    "                    generated_outputs[\"style\"],\n",
    "                )\n",
    "\n",
    "                total_loss = losses.style_content_loss(\n",
    "                    image=input_image,\n",
    "                    style_outputs=style_outputs,\n",
    "                    content_outputs=content_outputs,\n",
    "                    style_targets=style_targets,\n",
    "                    content_targets=content_targets,\n",
    "                )\n",
    "\n",
    "            # Calculate gradient of total loss with respect to input image\n",
    "            grad = tape.gradient(total_loss, input_image)\n",
    "            # Update input image\n",
    "            optim.apply_gradients([(grad, input_image)])\n",
    "\n",
    "            # Clip value of input image\n",
    "            input_image.assign(\n",
    "                tf.clip_by_value(input_image, clip_value_min=0.0, clip_value_max=1.0)\n",
    "            )\n",
    "\n",
    "            pbar.set_description(f\"Epoch {epoch}. Total loss : {total_loss}\")\n",
    "    return input_image\n",
    "\n",
    "\n",
    "\n",
    "content_image = helpers.load_image(\"/content/drive/MyDrive/Image_Style_Transfer/test_image/content_image/content_image_3.jpeg\")\n",
    "style_image = helpers.load_image(\"/content/drive/MyDrive/Image_Style_Transfer/test_image/style_image/artwork_2.jpeg\")\n",
    "\n",
    "content_image = tf.image.resize(content_image, [224, 224])\n",
    "style_image = tf.image.resize(style_image, [224, 224])\n",
    "\n",
    "generated_image = train(\n",
    "    epochs=40, content_image=content_image, style_image=style_image\n",
    ")\n",
    "\n",
    "plt.imshow(helpers.tensor_to_image(generated_image))\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
